{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aa23a8-6039-4ef1-9f8e-668e4f321221",
   "metadata": {},
   "source": [
    "# AI Math Problem Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ac446-c6da-4249-abcf-6c2df089085d",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc99eac-5526-4e52-a943-d0192e1af61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from google import generativeai\n",
    "\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420dfbc-e82f-4761-ba5b-ecc7013bc5bc",
   "metadata": {},
   "source": [
    "**Load API Keys & Connect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b23659d-7167-4794-816c-83a869187386",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4cb90b0-5efc-47b0-9d4a-dd483e5062c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the corresponding API's\n",
    "gpt = OpenAI(api_key = openai_key)\n",
    "claude = Anthropic(api_key = anthropic_key)\n",
    "generativeai.configure(api_key = google_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586168f-e80c-469e-88cd-1cdc78307f9b",
   "metadata": {},
   "source": [
    "**Define System & User Prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4563cb4f-d49b-4850-969e-5c83636f36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "system_prompt = \"You are an expert Math Teacher for students ranging from Grade 1 to Grade 12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4fbc8b-f9f4-4790-a947-24a9018fee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for User Prompt with three arguments\n",
    "def user_prompt(grade_level,num_problems, problem_type, difficulty_level, humour):\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_problems} math problems for Grade:{grade_level} and at a {difficulty_level} level for math problems of type:{problem_type}.\n",
    "    You can also create problems with this characteristic {humour}.\n",
    "    \n",
    "    Use the following format:\n",
    "    {problem_type}\n",
    "    --------------\n",
    "    'PROBLEMS:'\n",
    "        [problem]\n",
    "        [problem]\n",
    "        ...\n",
    "        ...\n",
    "    \n",
    "    Then, list the solutions similarly in a separate section labeled 'SOLUTIONS:' for each of the problem.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96316e12-f812-4c6d-b21f-4720a51757cb",
   "metadata": {},
   "source": [
    "### OpenAI - GPT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d925d8f-ff2d-4141-af44-0e52f792a67f",
   "metadata": {},
   "source": [
    "**Function to call OpenAI LLMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c47dbf-8658-4d87-a983-77ca241300d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_problems_gpt(grade_level, num_problems, problem_type,difficulty_level, humour):\n",
    "    completion = gpt.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\":\"system\", \"content\": system_prompt},\n",
    "            {\"role\":\"user\", \"content\": user_prompt(grade_level, num_problems,problem_type,difficulty_level, humour)}\n",
    "        ]\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f9acd8-2800-4257-83b5-a1c467bec287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Decimals-based Algebra**  \n",
      "--------------  \n",
      "**PROBLEMS:**  \n",
      "1. If Jenny has 5.75 meters of ribbon and she uses 2.25 meters for a craft project, how much ribbon does she have left?  \n",
      "2. A chocolate bar weighs 0.85 kg. If Tim eats 0.35 kg of it, how much does he have remaining?  \n",
      "3. In a quirky math class, each student has 2.40 liters of juice. If there are 5 students sharing their juice equally, how many liters does each student have left after they drink 1.20 liters?  \n",
      "4. A penguin waddles 3.15 kilometers to find fish. After catching some fish, he waddles back 1.80 kilometers. How far is he from his starting point now, if he forgets where he parked his igloo?  \n",
      "5. If a pizza weighs 1.25 kg and each slice weighs 0.25 kg, how many slices are in the pizza before anyone has a slice (and before it magically disappears!)?  \n",
      "\n",
      "**SOLUTIONS:**  \n",
      "1. 5.75 - 2.25 = 3.50 meters; Jenny has 3.50 meters of ribbon left.  \n",
      "2. 0.85 - 0.35 = 0.50 kg; Tim has 0.50 kg of chocolate bar left.  \n",
      "3. 2.40 - 1.20 = 1.20 liters; After drinking, each student has 1.20 liters left.  \n",
      "4. 3.15 - 1.80 = 1.35 kilometers; The penguin is 1.35 kilometers from its starting point (and still can't find the igloo!).  \n",
      "5. 1.25 / 0.25 = 5; There are 5 slices in the pizza before it magically disappears!\n"
     ]
    }
   ],
   "source": [
    "print (math_problems_gpt(4, 5,\"Decimals-based Algebra\",\"Difficult\", \"Funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51ac68-3d39-4fb7-bb04-238b41242fc3",
   "metadata": {},
   "source": [
    "**Function to call OpenAI LLM's with streaming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dccac5d0-ee88-47af-b6f5-d801e7073de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_math_problems_gpt(grade_level, num_problems,problem_type,difficulty_level, humour):\n",
    "    completion = gpt.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\":\"system\", \"content\": system_prompt},\n",
    "            {\"role\":\"user\", \"content\": user_prompt(grade_level, num_problems,problem_type,difficulty_level, humour)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "\n",
    "    result = \"\"\n",
    "    for text in completion:\n",
    "        result += text.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc572e7-1ea7-4e6e-adb8-5324e6d83077",
   "metadata": {},
   "source": [
    "### Anthropic  Claude Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f783a13a-ff59-405c-8653-e471c77d0f0c",
   "metadata": {},
   "source": [
    "**Function to call Claude model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afb7dd16-849d-434a-ba4f-69dd9e42a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_problems_claude(grade_level, num_problems, problem_type,difficulty_level, humour):\n",
    "    completion = claude.messages.create(\n",
    "        model = \"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        system = system_prompt,\n",
    "        messages = [\n",
    "            {\"role\":\"user\", \"content\": user_prompt(grade_level, num_problems,problem_type,difficulty_level, humour)}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = completion.content[0].text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5920cf3-98d9-4177-9439-3c731875d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (math_problems_claude(5,\"Decimals-based Algebra\",\"Easy\", \"Funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172a733-da98-4324-8cfa-40f55470fa35",
   "metadata": {},
   "source": [
    "**Function to call Claude Models with streaming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee702f7-5c71-4bae-ad5e-b998c5e6552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_math_problems_claude(grade_level, num_problems, problem_type,difficulty_level, humour):\n",
    "    completion = claude.messages.stream(\n",
    "        model = \"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        system = system_prompt,\n",
    "        messages = [\n",
    "            {\"role\":\"user\", \"content\": user_prompt(grade_level, num_problems,problem_type,difficulty_level, humour)}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    with completion as stream:\n",
    "        for text in stream.text_stream:\n",
    "            result += text or \"\"\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b2c4198-0c2f-45a4-bec2-fa7bf74299b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_problems(grade_level,num_problems, problem_type,difficulty_level, humour, model):\n",
    "    if model == \"Gpt\":\n",
    "        result = stream_math_problems_gpt(grade_level,num_problems, problem_type,difficulty_level, humour)\n",
    "    elif model == \"Claude\":\n",
    "        result = stream_math_problems_claude(grade_level,num_problems, problem_type,difficulty_level, humour)\n",
    "        \n",
    "    for chunk in result:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cd555d5-6c16-4be0-9245-2a29b89e751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object stream_math_problems_gpt at 0x000001D1595EDBD0>\n"
     ]
    }
   ],
   "source": [
    "print (stream_math_problems_gpt(5,5,'Decimals based algebra', 'medium', \"boring\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e825e69-b481-4d0b-afec-a20ff98151ff",
   "metadata": {},
   "source": [
    "### Simple Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed27d77-ecb3-4c76-989f-d04eb3cebf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All you need is to define the function which u want to call in the interface\n",
    "# specify the function arguments as inputs: Textboxes, dropdowns etc.\n",
    "# specify the corresponding Textbox for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a529e8-5c48-4084-a7f3-ae1cca7caf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\interface.py:393: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 2013, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\blocks.py\", line 1578, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 691, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 685, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2405, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 914, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 668, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py\", line 829, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sridh\\AppData\\Local\\Temp\\ipykernel_3276\\2192626003.py\", line 7, in math_problems\n",
      "    for chunk in result:\n",
      "                 ^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'result' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "# Gradio interface\n",
    "view = gr.Interface(\n",
    "    fn=math_problems,\n",
    "    inputs=[\n",
    "        gr.Textbox(label = \"Grade Level:\"),\n",
    "        gr.Textbox(label=\"Number of Problems:\"),\n",
    "        gr.Dropdown(choices=[\"Decimals-based Algebra\", \"Algebra\", \"Word Order Problems\", \"Geometry Problems\", ], label=\"Type of Problems\"),\n",
    "        gr.Dropdown(choices=[\"Easy\", \"Medium\", \"Difficult\"], label=\"Difficulty Level\"),\n",
    "        gr.Dropdown(choices=[\"Funny\", \"Scary\", \"Boring\"], label=\"Tone\"),\n",
    "        gr.Dropdown(choices=[\"Gpt\", \"Claude\"], label=\"AI Model\")\n",
    "    ], # number of inputs here need to match the arguments needed by the function which gradio will use (math\n",
    "    outputs=[\n",
    "        gr.Textbox(label = \"Result\"),\n",
    "    ],\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe5f87-e4f2-48d1-b066-65d110e949b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
